{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Regular expressions\n",
    "## Exercises: Regular expressions round 1.\n",
    "\n",
    "#### Now, explain in your own words: what are regular expressions?\n",
    "Regular expressions are sequence of characters that are used to identify patterns in a text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide an example of a regex to match 4 digits numbers (by this, I mean precisely 4 digits, you should not match any part of numbers with e.g. 5 digits). In your notebook, use findall to show that your regex works on this [test-text](https://raw.githubusercontent.com/suneman/socialgraphs2016/master/files/test.txt). Hint: a great place to test out regular expressions is: https://regex101.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1234', '9999', '2345']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "f = open('test.txt', 'r')\n",
    "strings = re.findall(r'\\d\\d\\d\\d', f.read())\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide an example of a regex to match words starting with \"super\". Show that it works on the [test-text](https://raw.githubusercontent.com/suneman/socialgraphs2016/master/files/test.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['superpolaroid', 'supertaxidermy', 'superbeer']\n"
     ]
    }
   ],
   "source": [
    "f = open('test.txt', 'r')\n",
    "strings = re.findall(r'super\\w+', f.read())\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Regular expressions round 2. Show that you can extract the wiki-links from the [test-text](https://raw.githubusercontent.com/suneman/socialgraphs2016/master/files/test.txt). Perhaps you can find inspiration on stack overflow or similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['drinking vinegar', 'gentrify', 'hashtag', 'Bicycle|Bicycle(two-wheeled type)', 'Pitchfork|Pitchfork Magazine']\n"
     ]
    }
   ],
   "source": [
    "f = open('test.txt', 'r')\n",
    "strings = re.findall(r'\\[\\[(.*?)\\]', f.read())\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A: Download Philosopher-pages from Wikipedia\n",
    "#### Exercise: Find the names of all the philosopher-pages, download and analyze them.\n",
    "\n",
    "[This wiki-page](https://en.wikipedia.org/wiki/Lists_of_philosophers) contains list of philosophers from various branches of philosophy:\n",
    "1. [aestheticians](https://en.wikipedia.org/wiki/List_of_aestheticians)\n",
    "2. [epistemologists](https://en.wikipedia.org/wiki/List_of_epistemologists)\n",
    "3. [ethicists](https://en.wikipedia.org/wiki/List_of_ethicists)\n",
    "4. [logicians](https://en.wikipedia.org/wiki/List_of_logicians)\n",
    "5. [metaphysicians](https://en.wikipedia.org/wiki/List_of_metaphysicians)\n",
    "6. [social and political philosophers](https://en.wikipedia.org/wiki/List_of_social_and_political_philosophers)\n",
    "\n",
    "We're going to have to go and extract the page names for all six groups of philosophers. Unfortunately wikipedia does not have a uniform way of setting such pages up, so you'll have to do each page differently. And I'd like you to maintain **seven** (7) separate lists of philosophers. One for each branch of philosophy - and one combined list of all philosophers.\n",
    "\n",
    "Let's put together some descriptive statistics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How many philosophers in each list? How many total?\n",
    "* Which is the largest branch of philosophy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aestheticians: 126\n",
      "epistemologists: 99\n",
      "ethicists: 272\n",
      "logicians: 273\n",
      "metaphysicians: 96\n",
      "social_and_political_philosophers: 295\n",
      "Total: 1161\n",
      "Largest branch: social_and_political_philosophers\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import re\n",
    "\n",
    "branches_of_phi = ['aestheticians', 'epistemologists',\n",
    "                   'ethicists', 'logicians', 'metaphysicians',\n",
    "                   'social_and_political_philosophers']\n",
    "\n",
    "total_phi = 0\n",
    "num_in_phi = []\n",
    "for phi in branches_of_phi:\n",
    "    f = io.open('./wikitext_' + phi + '.txt', 'r', encoding='utf8')\n",
    "    branch_of_phi = re.findall(r'\\[\\[(.*?)\\]\\]', f.read())\n",
    "    print(phi + ': ' + str(len(branch_of_phi)))\n",
    "    num_in_phi.append(len(branch_of_phi))\n",
    "    total_phi = total_phi + len(branch_of_phi)\n",
    "\n",
    "print('Total: ' + str(total_phi))\n",
    "\n",
    "largest_branch = max(xrange(len(num_in_phi)), key = lambda x: num_in_phi[x])\n",
    "print('Largest branch: ' + branches_of_phi[largest_branch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Are some philosophers in more than one list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Philosophers in more than one list: 115\n"
     ]
    }
   ],
   "source": [
    "all_phi = []\n",
    "for phi in branches_of_phi:\n",
    "    f = io.open('./wikitext_' + phi + '.txt', 'r', encoding='utf8')\n",
    "    branch_of_phi = re.findall(r'\\[\\[(.*?)\\]\\]', f.read())\n",
    "    all_phi = all_phi + branch_of_phi\n",
    "\n",
    "phi_duplicates = set([x for x in all_phi if all_phi.count(x) > 1])\n",
    "\n",
    "print('Philosophers in more than one list: ' + str(len(phi_duplicates)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Which philosopher is in most lists & and how many?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aristotle is in 6 lists\n",
      "Thomas Aquinas is in 6 lists\n"
     ]
    }
   ],
   "source": [
    "# Find how often philosophers appear in the combined list\n",
    "# and create a list how often they appear\n",
    "all_phi_num = []\n",
    "for i in all_phi:\n",
    "    all_phi_num.append(all_phi.count(i))\n",
    "\n",
    "# Find philosopher(s) who is/are in most lists by using\n",
    "# the max-value of the prev. list and create a new list\n",
    "find_most_phi = []\n",
    "for i in range(len(all_phi_num)):\n",
    "    if (all_phi_num[i] == max(all_phi_num)):\n",
    "        find_most_phi.append(all_phi[i])\n",
    "\n",
    "# Deleting duplicates from prev. list and sort\n",
    "most_phi = sorted(set(find_most_phi))      \n",
    "\n",
    "# Printing out the most philosopher(s)\n",
    "for phi in most_phi:\n",
    "    print(phi + ' is in ' + str(max(all_phi_num)) + ' lists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's investigate philosophers active in multiple sub-fields. Create a list of every philosopher that occurs in more than one list. Use Python to sort the list according to how many lists each philosopher belongs to (so the guy you found in the previous question is first in that list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aristotle is in 6 lists\n",
      "Thomas Aquinas is in 6 lists\n",
      "Bertrand Russell is in 5 lists\n",
      "Plato is in 5 lists\n",
      "Immanuel Kant is in 5 lists\n",
      "Ayn Rand is in 4 lists\n",
      "Judith Butler is in 3 lists\n",
      "Ruth Barcan Marcus is in 3 lists\n",
      "David Hume is in 3 lists\n",
      "John Locke is in 3 lists\n",
      "Mario Bunge is in 3 lists\n",
      "Søren Kierkegaard is in 3 lists\n",
      "Susan Haack is in 3 lists\n",
      "Ludwig Wittgenstein is in 3 lists\n",
      "John Stuart Mill is in 3 lists\n",
      "Nelson Goodman is in 3 lists\n",
      "Arthur Schopenhauer is in 3 lists\n",
      "Georg Wilhelm Friedrich Hegel is in 3 lists\n",
      "Penelope Maddy is in 2 lists\n",
      "John Hospers is in 2 lists\n",
      "Noam Chomsky is in 2 lists\n",
      "Baruch Spinoza is in 2 lists\n",
      "Kit Fine is in 2 lists\n",
      "Lorenzo Peña is in 2 lists\n",
      "Constantin Rădulescu-Motru is in 2 lists\n",
      "Max Stirner is in 2 lists\n",
      "Giambattista Vico is in 2 lists\n",
      "Karl Wilhelm Friedrich von Schlegel is in 2 lists\n",
      "Murray Bookchin is in 2 lists\n",
      "Gilbert Harman is in 2 lists\n",
      "Herbert Spencer is in 2 lists\n",
      "Abraham Joshua Heschel is in 2 lists\n",
      "Murray Rothbard is in 2 lists\n",
      "Saul Kripke is in 2 lists\n",
      "Catherine Elgin is in 2 lists\n",
      "Jean-Jacques Rousseau is in 2 lists\n",
      "Paul of Venice is in 2 lists\n",
      "Hilary Putnam is in 2 lists\n",
      "Thomas Hill Green is in 2 lists\n",
      "Graham Priest is in 2 lists\n",
      "Sally Haslanger is in 2 lists\n",
      "Maurice Blanchot is in 2 lists\n",
      "Friedrich Schiller is in 2 lists\n",
      "J. J. C. Smart is in 2 lists\n",
      "Robert S. Hartman is in 2 lists\n",
      "Mao Zedong is in 2 lists\n",
      "Gottfried Leibniz is in 2 lists\n",
      "Peter Unger is in 2 lists\n",
      "Mozi is in 2 lists\n",
      "Michel Foucault is in 2 lists\n",
      "Nader El-Bizri is in 2 lists\n",
      "Peter of Spain is in 2 lists\n",
      "Gualtiero Piccinini is in 2 lists\n",
      "Jeremy Bentham is in 2 lists\n",
      "Friedrich Nietzsche is in 2 lists\n",
      "Mortimer Adler is in 2 lists\n",
      "Michel Onfray is in 2 lists\n",
      "Alvin Plantinga is in 2 lists\n",
      "David Chalmers is in 2 lists\n",
      "Joxe Azurmendi is in 2 lists\n",
      "Joseph Raz is in 2 lists\n",
      "George Boole is in 2 lists\n",
      "John Searle is in 2 lists\n",
      "Alain Badiou is in 2 lists\n",
      "Martin Luther King, Jr. is in 2 lists\n",
      "Robert Nozick is in 2 lists\n",
      "Augustine of Hippo is in 2 lists\n",
      "Niccolò Machiavelli is in 2 lists\n",
      "John Ruskin is in 2 lists\n",
      "William Alston is in 2 lists\n",
      "T. M. Scanlon is in 2 lists\n",
      "Walter Terence Stace is in 2 lists\n",
      "Edward Said is in 2 lists\n",
      "Peter Kropotkin is in 2 lists\n",
      "Emma Goldman is in 2 lists\n",
      "Georges Bataille is in 2 lists\n",
      "Sun Yat-sen is in 2 lists\n",
      "Confucius is in 2 lists\n",
      "Henry Sidgwick is in 2 lists\n",
      "Thomas Nagel is in 2 lists\n",
      "Ludwig von Mises is in 2 lists\n",
      "Alfred North Whitehead is in 2 lists\n",
      "Berit Brogaard is in 2 lists\n",
      "Jürgen Habermas is in 2 lists\n",
      "Hugo Grotius is in 2 lists\n",
      "Peter Geach is in 2 lists\n",
      "Paul Benacerraf is in 2 lists\n",
      "David Kolb is in 2 lists\n",
      "Martha Nussbaum is in 2 lists\n",
      "George Berkeley is in 2 lists\n",
      "René Descartes is in 2 lists\n",
      "Philip Pettit is in 2 lists\n",
      "Francis Hutcheson (philosopher) is in 2 lists\n",
      "Walter Benjamin is in 2 lists\n",
      "G. E. Moore is in 2 lists\n",
      "Jean-François Lyotard is in 2 lists\n",
      "John Finnis is in 2 lists\n",
      "Francis Bacon is in 2 lists\n",
      "Karl Popper is in 2 lists\n",
      "William of Ockham is in 2 lists\n",
      "Jessica Wilson is in 2 lists\n",
      "Gottlob Frege is in 2 lists\n",
      "Thomas Hobbes is in 2 lists\n",
      "Karl-Otto Apel is in 2 lists\n",
      "Judith Jarvis Thomson is in 2 lists\n",
      "John Rawls is in 2 lists\n",
      "Socrates is in 2 lists\n",
      "Trenton Merricks is in 2 lists\n",
      "L.A. Paul is in 2 lists\n",
      "Martin Heidegger is in 2 lists\n",
      "Mencius is in 2 lists\n",
      "P. F. Strawson is in 2 lists\n",
      "John Hawthorne is in 2 lists\n",
      "Michael Oakeshott is in 2 lists\n",
      "Ronald Dworkin is in 2 lists\n"
     ]
    }
   ],
   "source": [
    "# Combining two lists (all_phi_num and all_phi) into one list\n",
    "if (len(all_phi) == len(all_phi_num)):\n",
    "    all_phi_two = zip(all_phi, all_phi_num)\n",
    "else:\n",
    "    print('Lists are not of the same length')\n",
    "\n",
    "# Deleting duplicates from prev. list\n",
    "more_phi = set(all_phi_two)\n",
    "\n",
    "# Sort the list according to how often the philosophers appear\n",
    "sorted_by_num = sorted(more_phi, key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "# Printing out philosophers that appear in more than one list\n",
    "for phi_two in sorted_by_num:\n",
    "    if (phi_two[1] > 1):\n",
    "        print(phi_two[0] + ' is in ' + str(phi_two[1]) + ' lists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Find the names of all the philosopher-pages, download and analyze them.\n",
    "\n",
    "Exercise: Download wikipages and save them to your own computer. For each of the philosophers in the combined list obtained in the previous exercise, use Wikipedia's API to download the full page content (using python) and save it (get it in json format, AND **don't** get the html version of the page which is much more difficult to parse).\n",
    "\n",
    "* Some pages contain unicode characters, so we recommend you save the files using the io.open method with utf-8 encoding\n",
    "* Some philosopher names have spaces. As a first stab, try to simply substitute spaces with underscores. (E.g. https://en.wikipedia.org/wiki/Thomas_Aquinas from Thomas Aquinas. If that doesn't work, you can construct the api-url using urllib.quote (or similar). This is another way of handling spaces using and other non-ascii characters in urls using [url encoding](http://www.w3schools.com/tags/ref_urlencode.asp).\n",
    "* Store the content of all pages. It's up to you how to do this. One strategy is to use Python's built in pickle format. Or you can simply write the content of wiki-pages to text files and store those in a folder on your computer. I'm sure there are other ways. It's crucial that you store them in a way that's easy to access, since we'll use these pages a lot throughout the remainder of the course (so you don't want to retrieve them from wikipedia every time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import json\n",
    "\n",
    "# Function for retrieving json data from Wikipedia\n",
    "def jsonWiki( name ):\n",
    "    # Parameters for retrieving page from wikipedia\n",
    "    baseurl = 'https://en.wikipedia.org/w/api.php?'\n",
    "    action = \"action=query\"\n",
    "    title = \"titles=\" + name\n",
    "    content = \"prop=revisions&rvprop=content\"\n",
    "    dataformat = \"format=json\"\n",
    "\n",
    "    # Construct the query\n",
    "    query = \"%s%s&%s&%s&%s\" % (baseurl, action, title, content, dataformat)\n",
    "\n",
    "    # Download json format of wikipedia page\n",
    "    wikiresponse = urllib2.urlopen(query)\n",
    "    wikisource = wikiresponse.read()\n",
    "    wikijson = json.loads(wikisource)\n",
    "    \n",
    "    return wikijson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Go through the list of philosophers and download their respective pages\n",
    "for p in range(len(sorted_by_num)):\n",
    "    #Convert philosophers' names from utf8 to string\n",
    "    name = sorted_by_num[p][0].encode(\"utf-8\")\n",
    "    \n",
    "    # Whitespace changed to underscore\n",
    "    name_url = re.sub('\\s+', '_', name)\n",
    "    \n",
    "    with io.open('./philosophers_json/' + name_url + '.json', 'w', encoding='utf8') as json_file:\n",
    "        json_file.write(unicode(json.dumps(jsonWiki(name_url), ensure_ascii=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part B: Building the networks\n",
    "Now, we're going to build a NetworkX directed graph of the links between pages. For each philosopher page, we'll find all the links to other characters, and for each link add an edge in the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Build the philosopher network. The **combined list** from above provides the network nodes. We will use info from the pages to define links. Every time philosopher A's page links to philosopher B's page, we create a directed link from A to B. There are many ways to do this, but below, I've tried to break it down into natural steps.\n",
    "\n",
    "* Use a regular expression to extract all outgoing links from each of the pages you downloaded above. There are many ways to iterate over pages - feel free to choose the one that matches the way you've chosen to store the pages.\n",
    "* For each link you extract, check if the target is in the list you generated above. If yes, keep it. If no, discard it.\n",
    "* Use a NetworkX [DiGraph](http://networkx.lanl.gov/reference/classes.digraph.html) to store the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
